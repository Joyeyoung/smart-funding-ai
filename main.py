from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import tensorflow as tf
from PIL import Image, UnidentifiedImageError
import numpy as np
import io, os

# HuggingFace ë²ˆì—­ê¸°ìš©
from transformers import MarianMTModel, MarianTokenizer

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# CORS ì„¤ì • (ëª¨ë“  ì¶œì²˜ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)

# ì •ì  íŒŒì¼ ì œê³µ (index.html ë“±)
app.mount("/static", StaticFiles(directory="."), name="static")

# ë£¨íŠ¸ ê²½ë¡œ ì²˜ë¦¬
@app.get("/", include_in_schema=False)
async def root():
    if os.path.exists("index.html"):
        return FileResponse("index.html", media_type="text/html")
    return JSONResponse({"message": "ì„œë¹„ìŠ¤ ì¤€ë¹„ ì™„ë£Œ"}, status_code=200)

# ëª¨ë¸ ë¡œë”© (MobileNetV2 ì‚¬ìš©)
model = None
def get_model():
    global model
    if model is None:
        try:
            print("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
            model = tf.keras.applications.MobileNetV2(weights="imagenet")
            print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            print("âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨:", str(e))
            raise RuntimeError("ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    return model

decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image_bytes):
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    except UnidentifiedImageError:
        raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    img = img.resize((224, 224))
    arr = tf.keras.applications.mobilenet_v2.preprocess_input(np.array(img))
    return np.expand_dims(arr, axis=0)

# ë¶„ë¥˜ ë¼ë²¨ì— ëŒ€í•œ í•œê¸€ ì •ë³´
LABEL_INFO = {
    "coffee_mug": {"feature": "ë¨¸ê·¸ì»µìœ¼ë¡œ ì¼ìƒì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë¦¬ë¹™ ì†Œí’ˆì…ë‹ˆë‹¤.", "ko_name": "ë¨¸ê·¸ì»µ"},
    "cup": {"feature": "ì»µìœ¼ë¡œ ë‹¤ì–‘í•œ ìŒë£Œë¥¼ ë‹´ì„ ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ì œí’ˆì…ë‹ˆë‹¤.", "ko_name": "ì»µ"},
    "laptop": {"feature": "ë…¸íŠ¸ë¶ìœ¼ë¡œ íœ´ëŒ€ì„±ê³¼ ì„±ëŠ¥ì„ ëª¨ë‘ ê°–ì¶˜ ì „ìê¸°ê¸°ì…ë‹ˆë‹¤.", "ko_name": "ë…¸íŠ¸ë¶"},
    "cellular_telephone": {"feature": "ìŠ¤ë§ˆíŠ¸í° ë“± íœ´ëŒ€ì „í™”ë¡œ í˜„ëŒ€ì¸ì˜ í•„ìˆ˜í’ˆì…ë‹ˆë‹¤.", "ko_name": "íœ´ëŒ€ì „í™”"},
    "swimming_trunks": {"feature": "ìˆ˜ì˜í•  ë•Œ ì…ëŠ” ë‚¨ì„±ìš© ìˆ˜ì˜ë³µì…ë‹ˆë‹¤.", "ko_name": "ìˆ˜ì˜ë³µ(ë‚¨ì„±ìš©)"}
}

# ë¼ë²¨ì„ í•œê¸€ë¡œ ë³€í™˜
def label_to_korean(label):
    return LABEL_INFO.get(label, {}).get("ko_name", label.replace('_', ' '))

# RGB ìƒ‰ìƒ â†’ ìƒ‰ìƒ ì´ë¦„ ì¶”ì •
def rgb_to_color_name(rgb):
    r, g, b = rgb
    if max(rgb) - min(rgb) < 20:
        mean_val = np.mean(rgb)
        return "í•˜ì–€ìƒ‰" if mean_val > 200 else "ê²€ì€ìƒ‰" if mean_val < 50 else "íšŒìƒ‰"
    if r > 200 and g > 200 and b < 100: return "ë…¸ë€ìƒ‰"
    if r > 200 and g < 100 and b < 100: return "ë¹¨ê°„ìƒ‰"
    if r < 100 and g > 200 and b < 100: return "ì´ˆë¡ìƒ‰"
    if r < 100 and g < 100 and b > 200: return "íŒŒë€ìƒ‰"
    if r > 200 and g < 100 and b > 200: return "ë¶„í™ìƒ‰"
    if r > 200 and g > 100 and b > 100: return "ë² ì´ì§€ìƒ‰"
    return "ê¸°íƒ€"

# ìƒ‰ìƒ í‰ê· ìœ¼ë¡œ ì¬ì§ˆ ì¶”ì •
def guess_material(rgb):
    mean_val = np.mean(rgb)
    if mean_val > 200: return "í”Œë¼ìŠ¤í‹±/ì„¸ë¼ë¯¹"
    if mean_val < 60: return "ê¸ˆì†/ê³ ë¬´"
    if all(abs(rgb[i] - rgb[i + 1]) < 20 for i in range(2)) and 100 < mean_val < 200:
        return "ì²œ/íŒ¨ë¸Œë¦­"
    return "ë³µí•©/ê¸°íƒ€"

# ì´ë¯¸ì§€ ë””ìì¸ ì •ë³´ ë¶„ì„ (ìƒ‰ìƒ, ì¬ì§ˆ)
def analyze_design(image_bytes):
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGB").resize((100, 100))
    except UnidentifiedImageError:
        raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨")
    avg_color = np.mean(np.array(img).reshape(-1, 3), axis=0)
    return {
        "main_color": rgb_to_color_name(avg_color),
        "material": guess_material(avg_color)
    }

# HuggingFace ì˜ì–´ â†’ í•œêµ­ì–´ ë²ˆì—­ê¸° ì´ˆê¸°í™”
tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-ko")
model_translator = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-en-ko")

# í…ìŠ¤íŠ¸ ìë™ ë²ˆì—­ í•¨ìˆ˜
def translate_to_korean(text):
    try:
        tokens = tokenizer.prepare_seq2seq_batch([text], return_tensors="pt")
        translated = model_translator.generate(**tokens)
        return tokenizer.decode(translated[0], skip_special_tokens=True)
    except Exception as e:
        return f"[ë²ˆì—­ ì˜¤ë¥˜] {str(e)}"

# í”Œë«í¼ ì í•©ë„ ì¶”ì • í•¨ìˆ˜ (ê°„ì´ AI ë£° ê¸°ë°˜)
def infer_suitability(label, design):
    color = design["main_color"]
    material = design["material"]
    score = {}

    if "mug" in label or "cup" in label:
        score = {"ì™€ë””ì¦ˆ": 90, "í‚¥ìŠ¤íƒ€í„°": 60, "ë§ˆì¿ ì•„ê²Œ": 70, "ì ì ": 65}
    elif "laptop" in label or "cellular" in label:
        score = {"ì™€ë””ì¦ˆ": 55, "í‚¥ìŠ¤íƒ€í„°": 95, "ë§ˆì¿ ì•„ê²Œ": 60, "ì ì ": 75}
    else:
        score = {"ì™€ë””ì¦ˆ": 60, "í‚¥ìŠ¤íƒ€í„°": 60, "ë§ˆì¿ ì•„ê²Œ": 85, "ì ì ": 90}

    # ìƒ‰ìƒ/ì¬ì§ˆ ì¶”ê°€ ê°€ì¤‘ì¹˜
    if color == "ê²€ì€ìƒ‰" and material == "ê¸ˆì†/ê³ ë¬´":
        score = {k: min(v + 5, 100) for k, v in score.items()}
    elif color == "ë…¸ë€ìƒ‰" or material == "í”Œë¼ìŠ¤í‹±/ì„¸ë¼ë¯¹":
        score["ì™€ë””ì¦ˆ"] = min(score.get("ì™€ë””ì¦ˆ", 60) + 10, 100)

    return score

# ì£¼ìš” API: ì´ë¯¸ì§€ ì—…ë¡œë“œ í›„ í”Œë«í¼ ì¶”ì²œ
@app.post("/api/recommend-platform")
async def recommend_platform(image: UploadFile = File(...)):
    try:
        image_bytes = await image.read()
        input_tensor = preprocess_image(image_bytes)
        preds = get_model().predict(input_tensor)
        label = decode_predictions(preds, top=1)[0][0][1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    label_ko = label_to_korean(label)
    info = LABEL_INFO.get(label, {"feature": f"{label_ko}(ìœ¼)ë¡œ ë¶„ë¥˜ëœ ì œí’ˆì…ë‹ˆë‹¤."})
    design_info = analyze_design(image_bytes)
    suitability = infer_suitability(label, design_info)

    # í”Œë«í¼ ì¶”ì²œ ë¡œì§
    if "mug" in label or "cup" in label:
        platform, category, reason = "ì™€ë””ì¦ˆ", "ë¦¬ë¹™ ì†Œí’ˆ", "ë¨¸ê·¸ì»µ ë“± ë¦¬ë¹™ ì œí’ˆì€ êµ­ë‚´ í”Œë«í¼ì— ì í•©í•©ë‹ˆë‹¤."
    elif "laptop" in label or "cellular" in label:
        platform, category, reason = "í‚¥ìŠ¤íƒ€í„°", "í…Œí¬/ë””ìì¸", "í…Œí¬ ì œí’ˆì€ ê¸€ë¡œë²Œ ì‹œì¥ì— ì í•©í•©ë‹ˆë‹¤."
    else:
        platform, category, reason = "ì ì ", "ë¼ì´í”„ìŠ¤íƒ€ì¼", f"'{label_ko}' ê´€ë ¨ ì œí’ˆì€ ë™ë‚¨ì•„ ì‹œì¥ì— ì í•©í•©ë‹ˆë‹¤."

    translated_reason = translate_to_korean(reason)

    return {
        "platform": platform,
        "category": category,
        "reason": reason,
        "reason_ko": translated_reason,
        "feature": info["feature"],
        "label_ko": label_ko,
        "design": design_info,
        "suitability": suitability
    }

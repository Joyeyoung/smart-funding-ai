from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import tensorflow as tf
from PIL import Image, UnidentifiedImageError
import numpy as np
import io, os

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/static", StaticFiles(directory="."), name="static")

# ë£¨íŠ¸ ê²½ë¡œ
@app.get("/", include_in_schema=False)
async def root():
    if os.path.exists("index.html"):
        return FileResponse("index.html", media_type="text/html")
    return JSONResponse({"message": "ì„œë¹„ìŠ¤ ì¤€ë¹„ ì™„ë£Œ"}, status_code=200)

# ëª¨ë¸ lazy-load
model = None
def get_model():
    global model
    if model is None:
        try:
            print("ğŸ“¦ MobileNetV2 ëª¨ë¸ ë¡œë”© ì¤‘...")
            model = tf.keras.applications.MobileNetV2(weights="imagenet")
            print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            raise RuntimeError(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
    return model

decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
def preprocess_image(image_bytes):
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    except UnidentifiedImageError:
        raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    img = img.resize((224, 224))
    arr = tf.keras.applications.mobilenet_v2.preprocess_input(np.array(img))
    return np.expand_dims(arr, axis=0)

# ë¼ë²¨ ì •ë³´ ë° ë²ˆì—­ ëŒ€ì‘
LABEL_INFO = {
    "coffee_mug": {"feature": "ë¨¸ê·¸ì»µìœ¼ë¡œ ì¼ìƒì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë¦¬ë¹™ ì†Œí’ˆì…ë‹ˆë‹¤.", "ko_name": "ë¨¸ê·¸ì»µ"},
    "cup": {"feature": "ì»µìœ¼ë¡œ ë‹¤ì–‘í•œ ìŒë£Œë¥¼ ë‹´ì„ ìˆ˜ ìˆëŠ” ì‹¤ìš©ì ì¸ ì œí’ˆì…ë‹ˆë‹¤.", "ko_name": "ì»µ"},
    "laptop": {"feature": "ë…¸íŠ¸ë¶ìœ¼ë¡œ íœ´ëŒ€ì„±ê³¼ ì„±ëŠ¥ì„ ëª¨ë‘ ê°–ì¶˜ ì „ìê¸°ê¸°ì…ë‹ˆë‹¤.", "ko_name": "ë…¸íŠ¸ë¶"},
    "cellular_telephone": {"feature": "ìŠ¤ë§ˆíŠ¸í° ë“± íœ´ëŒ€ì „í™”ë¡œ í˜„ëŒ€ì¸ì˜ í•„ìˆ˜í’ˆì…ë‹ˆë‹¤.", "ko_name": "íœ´ëŒ€ì „í™”"},
    "swimming_trunks": {"feature": "ìˆ˜ì˜í•  ë•Œ ì…ëŠ” ë‚¨ì„±ìš© ìˆ˜ì˜ë³µì…ë‹ˆë‹¤.", "ko_name": "ìˆ˜ì˜ë³µ(ë‚¨ì„±ìš©)"}
}

def label_to_korean(label):
    return LABEL_INFO.get(label, {}).get("ko_name", label.replace('_', ' '))

def rgb_to_color_name(rgb):
    r, g, b = rgb
    if max(rgb) - min(rgb) < 20:
        mean_val = np.mean(rgb)
        return "í•˜ì–€ìƒ‰" if mean_val > 200 else "ê²€ì€ìƒ‰" if mean_val < 50 else "íšŒìƒ‰"
    if r > 200 and g > 200 and b < 100: return "ë…¸ë€ìƒ‰"
    if r > 200 and g < 100 and b < 100: return "ë¹¨ê°„ìƒ‰"
    if r < 100 and g > 200 and b < 100: return "ì´ˆë¡ìƒ‰"
    if r < 100 and g < 100 and b > 200: return "íŒŒë€ìƒ‰"
    if r > 200 and g < 100 and b > 200: return "ë¶„í™ìƒ‰"
    if r > 200 and g > 100 and b > 100: return "ë² ì´ì§€ìƒ‰"
    return "ê¸°íƒ€"

def guess_material(rgb):
    mean_val = np.mean(rgb)
    if mean_val > 200: return "í”Œë¼ìŠ¤í‹±/ì„¸ë¼ë¯¹"
    if mean_val < 60: return "ê¸ˆì†/ê³ ë¬´"
    if all(abs(rgb[i] - rgb[i + 1]) < 20 for i in range(2)) and 100 < mean_val < 200:
        return "ì²œ/íŒ¨ë¸Œë¦­"
    return "ë³µí•©/ê¸°íƒ€"

def analyze_design(image_bytes):
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGB").resize((100, 100))
    except UnidentifiedImageError:
        raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨")
    avg_color = np.mean(np.array(img).reshape(-1, 3), axis=0)
    return {
        "main_color": rgb_to_color_name(avg_color),
        "material": guess_material(avg_color)
    }

# í”Œë«í¼ ì í•©ë„ ê°„ì´ ì¶”ë¡ 
def infer_suitability(label, design):
    color = design["main_color"]
    material = design["material"]
    score = {}

    if "mug" in label or "cup" in label:
        score = {"ì™€ë””ì¦ˆ": 90, "í‚¥ìŠ¤íƒ€í„°": 60, "ë§ˆì¿ ì•„ê²Œ": 70, "ì ì ": 65}
    elif "laptop" in label or "cellular" in label:
        score = {"ì™€ë””ì¦ˆ": 55, "í‚¥ìŠ¤íƒ€í„°": 95, "ë§ˆì¿ ì•„ê²Œ": 60, "ì ì ": 75}
    else:
        score = {"ì™€ë””ì¦ˆ": 60, "í‚¥ìŠ¤íƒ€í„°": 60, "ë§ˆì¿ ì•„ê²Œ": 85, "ì ì ": 90}

    # ìƒ‰ìƒ/ì¬ì§ˆ ì˜í–¥ ì¶”ê°€
    if color == "ê²€ì€ìƒ‰" and material == "ê¸ˆì†/ê³ ë¬´":
        score = {k: min(v + 5, 100) for k, v in score.items()}
    elif color == "ë…¸ë€ìƒ‰" or material == "í”Œë¼ìŠ¤í‹±/ì„¸ë¼ë¯¹":
        score["ì™€ë””ì¦ˆ"] = min(score.get("ì™€ë””ì¦ˆ", 60) + 10, 100)

    return score

# API: ì´ë¯¸ì§€ ì—…ë¡œë“œ í›„ í”Œë«í¼ ì¶”ì²œ
@app.post("/api/recommend-platform")
async def recommend_platform(image: UploadFile = File(...)):
    try:
        image_bytes = await image.read()
        input_tensor = preprocess_image(image_bytes)
        model_local = get_model()
        preds = model_local.predict(input_tensor)
        label = decode_predictions(preds, top=1)[0][0][1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")

    label_ko = label_to_korean(label)
    info = LABEL_INFO.get(label, {"feature": f"{label_ko}(ìœ¼)ë¡œ ë¶„ë¥˜ëœ ì œí’ˆì…ë‹ˆë‹¤."})
    design_info = analyze_design(image_bytes)
    suitability = infer_suitability(label, design_info)

    if "mug" in label or "cup" in label:
        platform, category, reason = "ì™€ë””ì¦ˆ", "ë¦¬ë¹™ ì†Œí’ˆ", "ë¨¸ê·¸ì»µ ë“± ë¦¬ë¹™ ì œí’ˆì€ êµ­ë‚´ í”Œë«í¼ì— ì í•©í•©ë‹ˆë‹¤."
    elif "laptop" in label or "cellular" in label:
        platform, category, reason = "í‚¥ìŠ¤íƒ€í„°", "í…Œí¬/ë””ìì¸", "í…Œí¬ ì œí’ˆì€ ê¸€ë¡œë²Œ ì‹œì¥ì— ì í•©í•©ë‹ˆë‹¤."
    else:
        platform, category, reason = "ì ì ", "ë¼ì´í”„ìŠ¤íƒ€ì¼", f"'{label_ko}' ê´€ë ¨ ì œí’ˆì€ ë™ë‚¨ì•„ ì‹œì¥ì— ì í•©í•©ë‹ˆë‹¤."

    return {
        "platform": platform,
        "category": category,
        "reason": reason,
        "feature": info["feature"],
        "label_ko": label_ko,
        "design": design_info,
        "suitability": suitability
    }
